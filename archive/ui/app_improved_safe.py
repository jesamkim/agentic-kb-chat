"""
Improved MCP RAG Chatbot - Safe Streamlit UI
ì•ˆì „í•œ ê°œì„ ëœ ë°ì´í„° íë¦„ì„ ì§€ì›í•˜ëŠ” Streamlit UI
"""

import streamlit as st
import sys
import os
import base64
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from PIL import Image
import io
import time
import threading
from queue import Queue

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.append('/Workshop/agentic-kb-chat')

from src.agents.react_agent_improved_safe import improved_react_agent  # ì•ˆì „í•œ ë²„ì „ ì‚¬ìš©
from src.utils.session import SessionManager
from config.settings import settings

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Enhanced MCP RAG Chatbot (Safe)",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "session_id" not in st.session_state:
    st.session_state.session_id = None
if "improved_react_agent" not in st.session_state:
    st.session_state.improved_react_agent = None
if "session_manager" not in st.session_state:
    st.session_state.session_manager = None
if "kb_id" not in st.session_state:
    st.session_state.kb_id = "CQLBN9MFDZ"
if "ui_updates" not in st.session_state:
    st.session_state.ui_updates = Queue()
if "current_progress" not in st.session_state:
    st.session_state.current_progress = {}


def initialize_improved_agents(kb_id: str):
    """ê°œì„ ëœ Agent ë° ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
    try:
        # KB_ID ì„¤ì • ì—…ë°ì´íŠ¸
        settings.knowledge_base.kb_id = kb_id
        
        # ê°œì„ ëœ Agent ì´ˆê¸°í™” (ì•ˆì „í•œ ë²„ì „)
        react_agent = improved_react_agent
        session_manager = SessionManager()
        
        return react_agent, session_manager
    except Exception as e:
        st.error(f"ê°œì„ ëœ Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None, None


def ui_callback(update_type: str, data: Dict[str, Any]):
    """UI ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜"""
    try:
        # ì„¸ì…˜ ìƒíƒœì— ì—…ë°ì´íŠ¸ ì €ì¥
        st.session_state.ui_updates.put({
            "type": update_type,
            "data": data,
            "timestamp": datetime.now().isoformat()
        })
        
        # í˜„ì¬ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        if update_type == "stage_update":
            stage = data.get("stage", "unknown")
            message = data.get("message", "")
            st.session_state.current_progress[stage] = {
                "message": message,
                "timestamp": datetime.now().isoformat(),
                "data": data
            }
        elif update_type in ["tool_call_start", "tool_call_complete", "tool_call_failed"]:
            # Tool í˜¸ì¶œ ì •ë³´ ì—…ë°ì´íŠ¸
            call_info = data
            call_id = call_info.get("call_id", "unknown")
            st.session_state.current_progress[f"tool_call_{call_id}"] = call_info
            
    except Exception as e:
        print(f"UI ì½œë°± ì˜¤ë¥˜: {e}")


def display_enhanced_progress():
    """ê°œì„ ëœ ì§„í–‰ ìƒí™© í‘œì‹œ"""
    if not st.session_state.current_progress:
        return
    
    progress_container = st.container()
    
    with progress_container:
        st.markdown("### ğŸ”„ ì²˜ë¦¬ ì§„í–‰ ìƒí™©")
        
        # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™©
        stages = [
            ("intent_analysis", "ğŸ§  ì˜ë„ ë¶„ì„"),
            ("multi_stage_search", "ğŸ” ë‹¤ë‹¨ê³„ ê²€ìƒ‰"),
            ("response_generation", "ğŸ“ ì‘ë‹µ ìƒì„±")
        ]
        
        cols = st.columns(len(stages))
        
        for i, (stage_key, stage_name) in enumerate(stages):
            with cols[i]:
                if stage_key in st.session_state.current_progress:
                    stage_info = st.session_state.current_progress[stage_key]
                    message = stage_info.get("message", "")
                    
                    if "ì™„ë£Œ" in message or "âœ…" in message:
                        st.success(f"{stage_name} âœ…")
                    elif "ì¤‘" in message or "â³" in message:
                        st.info(f"{stage_name} â³")
                    else:
                        st.info(f"{stage_name} â¸ï¸")
                else:
                    st.info(f"{stage_name} â¸ï¸")
        
        # Tool í˜¸ì¶œ ìƒì„¸ ì •ë³´
        tool_calls = [
            key for key in st.session_state.current_progress.keys() 
            if key.startswith("tool_call_")
        ]
        
        if tool_calls:
            st.markdown("#### ğŸ”§ MCP Tool í˜¸ì¶œ ìƒí™©")
            
            for tool_call_key in tool_calls[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
                call_info = st.session_state.current_progress[tool_call_key]
                ui_message = call_info.get("ui_message", "")
                status = call_info.get("status", "unknown")
                
                if status == "completed":
                    st.success(ui_message)
                elif status == "running":
                    st.info(ui_message)
                elif status == "failed":
                    st.error(ui_message)
                else:
                    st.info(ui_message)


def display_intent_analysis_results(analysis_result: Dict[str, Any]):
    """ì˜ë„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    if not analysis_result:
        return
    
    with st.expander("ğŸ§  ì˜ë„ ë¶„ì„ ê²°ê³¼", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "ì£¼ìš” ì˜ë„", 
                analysis_result.get("primary_intent", "unknown").replace("_", " ")
            )
        
        with col2:
            st.metric(
                "ë³µì¡ë„", 
                analysis_result.get("complexity", "ë³´í†µ")
            )
        
        with col3:
            additional_searches = analysis_result.get("requires_additional_search", False)
            st.metric(
                "ì¶”ê°€ ê²€ìƒ‰", 
                "í•„ìš”" if additional_searches else "ë¶ˆí•„ìš”"
            )
        
        # ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬
        additional_queries = analysis_result.get("additional_search_queries", [])
        if additional_queries:
            st.markdown("**ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬:**")
            for i, query in enumerate(additional_queries, 1):
                st.markdown(f"{i}. {query}")
        
        # í•µì‹¬ ì—”í‹°í‹°
        key_entities = analysis_result.get("key_entities", [])
        if key_entities:
            st.markdown("**í•µì‹¬ ì—”í‹°í‹°:**")
            st.markdown(", ".join(key_entities))


def display_search_quality_metrics(search_results: Dict[str, Any]):
    """ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ"""
    quality_metrics = search_results.get("quality_metrics", {})
    if not quality_metrics:
        return
    
    with st.expander("ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­", expanded=False):
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ì „ì²´ í’ˆì§ˆ", 
                f"{quality_metrics.get('overall_quality', 0):.2f}",
                help="ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆ ì ìˆ˜"
            )
        
        with col2:
            st.metric(
                "ê´€ë ¨ì„±", 
                f"{quality_metrics.get('relevance_score', 0):.2f}",
                help="ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± ì ìˆ˜"
            )
        
        with col3:
            st.metric(
                "ì»¤ë²„ë¦¬ì§€", 
                f"{quality_metrics.get('coverage_score', 0):.2f}",
                help="í•µì‹¬ ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€ ì ìˆ˜"
            )
        
        with col4:
            st.metric(
                "ë‹¤ì–‘ì„±", 
                f"{quality_metrics.get('diversity_score', 0):.2f}",
                help="ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„± ì ìˆ˜"
            )


def display_response_quality_metrics(response_metadata: Dict[str, Any]):
    """ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ"""
    response_quality = response_metadata.get("response_quality", {})
    token_usage = response_metadata.get("token_usage", {})
    
    if not response_quality and not token_usage:
        return
    
    with st.expander("ğŸ“ ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­", expanded=False):
        if response_quality:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ì „ì²´ í’ˆì§ˆ", 
                    f"{response_quality.get('overall_quality', 0):.2f}"
                )
            
            with col2:
                st.metric(
                    "êµ¬ì¡°í™” ì ìˆ˜", 
                    f"{response_quality.get('structure_score', 0):.2f}"
                )
            
            with col3:
                st.metric(
                    "ì˜ë„ ì¶©ì¡±ë„", 
                    f"{response_quality.get('intent_score', 0):.2f}"
                )
            
            with col4:
                st.metric(
                    "Citation í™œìš©", 
                    f"{response_quality.get('citation_score', 0):.2f}"
                )
        
        if token_usage:
            st.markdown("**í† í° ì‚¬ìš©ëŸ‰:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì´ í† í°", token_usage.get("total_tokens", 0))
            
            with col2:
                st.metric("ë‹¨ì–´ ìˆ˜", token_usage.get("word_count", 0))
            
            with col3:
                utilization = token_usage.get("utilization_rate", 0)
                st.metric("ì‚¬ìš©ë¥ ", f"{utilization}%")
                
                # ì‚¬ìš©ë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                if utilization > 90:
                    st.warning("í† í° ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ (90% ì´ìƒ)")
                elif utilization > 70:
                    st.info("í† í° ì‚¬ìš©ë¥ ì´ ì ì ˆí•©ë‹ˆë‹¤ (70-90%)")


def process_enhanced_query_with_progress(query: str, image_data: Optional[str] = None):
    """ê°œì„ ëœ ì§„í–‰ ìƒí™© í‘œì‹œì™€ í•¨ê»˜ ì¿¼ë¦¬ ì²˜ë¦¬"""
    
    # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
    st.session_state.current_progress = {}
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ ì˜ì—­
    progress_placeholder = st.empty()
    
    try:
        # ê°œì„ ëœ ReAct Agentë¡œ ì²˜ë¦¬ (ì•ˆì „í•œ ë²„ì „)
        result = st.session_state.improved_react_agent.process_query_enhanced(
            user_query=query,
            session_id=st.session_state.session_id,
            image_data=image_data,
            ui_callback=ui_callback
        )
        
        # ìµœì¢… ì§„í–‰ ìƒí™© í‘œì‹œ
        with progress_placeholder.container():
            st.markdown("### âœ… ì²˜ë¦¬ ì™„ë£Œ")
            
            # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result.get('total_processing_time', 0):.1f}ì´ˆ")
            
            with col2:
                st.metric("ë°˜ë³µ íšŸìˆ˜", f"{result.get('iterations_used', 0)}íšŒ")
            
            with col3:
                st.metric("Citation ìˆ˜", f"{len(result.get('citations', []))}")
            
            with col4:
                search_stages = len(result.get("metadata", {}).get("search_stages", []))
                st.metric("ê²€ìƒ‰ ë‹¨ê³„", f"{search_stages}ë‹¨ê³„")
            
            # ê°œì„ ëœ ê¸°ëŠ¥ ì‚¬ìš© í˜„í™©
            enhanced_features = result.get("enhanced_features", {})
            if enhanced_features:
                st.markdown("**ì‚¬ìš©ëœ ê°œì„  ê¸°ëŠ¥:**")
                feature_status = []
                
                if enhanced_features.get("intent_analysis"):
                    feature_status.append("ğŸ§  ì˜ë„ ë¶„ì„")
                if enhanced_features.get("multi_stage_search"):
                    feature_status.append("ğŸ” ë‹¤ë‹¨ê³„ ê²€ìƒ‰")
                if enhanced_features.get("token_limited_response"):
                    feature_status.append("ğŸ“ í† í° ì œí•œ ì‘ë‹µ")
                if enhanced_features.get("tool_call_tracking"):
                    feature_status.append("ğŸ”§ Tool í˜¸ì¶œ ì¶”ì ")
                
                st.markdown(" | ".join(feature_status))
        
        return result
        
    except Exception as e:
        progress_placeholder.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def main():
    # í—¤ë”
    st.title("ğŸ¤– Enhanced MCP RAG Chatbot (Safe)")
    st.markdown("ê°œì„ ëœ ReAct ê¸°ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ - ì•ˆì „í•œ í† í° ì²˜ë¦¬ ë²„ì „")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ê°œì„ ëœ ì„¤ì • (Safe)")
        
        # KB_ID ì„¤ì •
        st.subheader("Knowledge Base ì„¤ì •")
        new_kb_id = st.text_input(
            "KB_ID",
            value=st.session_state.kb_id,
            help="Amazon Bedrock Knowledge Base ID"
        )
        
        if new_kb_id != st.session_state.kb_id:
            st.session_state.kb_id = new_kb_id
            st.session_state.improved_react_agent = None
            st.session_state.session_manager = None
            st.rerun()
        
        # ê°œì„ ëœ Agent ì´ˆê¸°í™”
        if st.session_state.improved_react_agent is None or st.session_state.session_manager is None:
            with st.spinner("ê°œì„ ëœ Agent ì´ˆê¸°í™” ì¤‘..."):
                react_agent, session_manager = initialize_improved_agents(st.session_state.kb_id)
                if react_agent and session_manager:
                    st.session_state.improved_react_agent = react_agent
                    st.session_state.session_manager = session_manager
                    st.success("ê°œì„ ëœ Agent ì´ˆê¸°í™” ì™„ë£Œ!")
                else:
                    st.error("Agent ì´ˆê¸°í™” ì‹¤íŒ¨")
                    st.stop()
        
        # ì„¸ì…˜ ê´€ë¦¬
        st.subheader("ì„¸ì…˜ ê´€ë¦¬")
        if st.button("ğŸ†• ìƒˆ ëŒ€í™” ì‹œì‘"):
            if st.session_state.session_manager:
                session = st.session_state.session_manager.create_session()
                st.session_state.session_id = session.session_id
                st.session_state.messages = []
                st.session_state.current_progress = {}
                st.success("ìƒˆ ì„¸ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        if st.session_state.session_id:
            st.info(f"ì„¸ì…˜ ID: {st.session_state.session_id[:8]}...")
        
        st.divider()
        
        # ê°œì„ ëœ ì‹œìŠ¤í…œ ì •ë³´
        st.subheader("ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ì‹œìŠ¤í…œ ê²€ì¦
        if st.session_state.improved_react_agent:
            validation_result = st.session_state.improved_react_agent.validate_enhanced_system()
            system_status = validation_result.get("system_status", "unknown")
            
            if system_status == "healthy":
                st.success("âœ… ëª¨ë“  ê°œì„  ê¸°ëŠ¥ ì •ìƒ ì‘ë™")
            elif system_status == "degraded":
                st.warning(f"âš ï¸ ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ: {validation_result.get('issues', '')}")
            else:
                st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {validation_result.get('error', '')}")
        
        # ê°œì„  ê¸°ëŠ¥ ëª©ë¡
        st.info(f"""
        **ê°œì„ ëœ ê¸°ëŠ¥ë“¤ (Safe Version):**
        ğŸ§  **ì˜ë„ ë¶„ì„**: ì‚¬ìš©ì ì¿¼ë¦¬ ì˜ë„ ìë™ íŒŒì•…
        ğŸ” **ë‹¤ë‹¨ê³„ ê²€ìƒ‰**: 1ì°¨ ê²€ìƒ‰ + ì¶”ê°€ ê²€ìƒ‰ (ìµœëŒ€ 5íšŒ)
        ğŸ“ **í† í° ì œí•œ**: 3000 í† í° ì´ë‚´ ì‘ë‹µ ìƒì„± (ì•ˆì „ ì²˜ë¦¬)
        ğŸ”§ **Tool ì¶”ì **: MCP Tool í˜¸ì¶œ ì‹¤ì‹œê°„ í‘œì‹œ
        ğŸ“Š **í’ˆì§ˆ ë©”íŠ¸ë¦­**: ê²€ìƒ‰ ë° ì‘ë‹µ í’ˆì§ˆ ì¸¡ì •
        
        **KB_ID**: {st.session_state.kb_id}
        **ëª¨ë¸**: Claude 3.7 Sonnet
        **í† í° ì²˜ë¦¬**: tiktoken ì•ˆì „ fallback ì§€ì›
        """)
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    if not st.session_state.session_id and st.session_state.session_manager:
        session = st.session_state.session_manager.create_session()
        st.session_state.session_id = session.session_id
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            if message["role"] == "user":
                st.markdown(message["content"])
                if "image" in message:
                    st.image(message["image"], caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€", width=300)
            else:
                st.markdown(message["content"])
                
                # ê°œì„ ëœ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                if "metadata" in message:
                    metadata = message["metadata"]
                    
                    # ì˜ë„ ë¶„ì„ ê²°ê³¼
                    if "intent_analysis" in metadata:
                        display_intent_analysis_results(metadata["intent_analysis"])
                    
                    # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­
                    if "search_quality" in metadata:
                        display_search_quality_metrics({"quality_metrics": metadata["search_quality"]})
                    
                    # ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­
                    if "response_quality" in metadata or "token_usage" in metadata:
                        display_response_quality_metrics({
                            "response_quality": metadata.get("response_quality", {}),
                            "token_usage": metadata.get("token_usage", {})
                        })
                
                # Citation í‘œì‹œ
                if "citations" in message and message["citations"]:
                    # ê¸°ì¡´ Citation í‘œì‹œ í•¨ìˆ˜ ì‚¬ìš©
                    try:
                        from ui.app import display_citation_expandable_with_id
                        message_id = f"safe_msg_{idx}_{hash(str(message.get('timestamp', '')))}"
                        display_citation_expandable_with_id(message["citations"], message["content"], message_id)
                    except ImportError:
                        # ê¸°ë³¸ Citation í‘œì‹œ
                        st.markdown("### ğŸ“š ì°¸ê³  ë¬¸ì„œ")
                        for i, citation in enumerate(message["citations"], 1):
                            filename = citation.get("document_title", f"ë¬¸ì„œ_{i}")
                            with st.expander(f"[{i}] {filename}", expanded=False):
                                preview = citation.get("preview", "")
                                if preview:
                                    st.text_area("ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", value=preview, height=100, disabled=True)
    
    # ì±„íŒ… ì…ë ¥ ì˜ì—­
    st.markdown("### ğŸ’¬ ë©”ì‹œì§€ ì…ë ¥")
    
    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ ì²¨ë¶€ (ì„ íƒì‚¬í•­)",
        type=['png', 'jpg', 'jpeg'],
        help="ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    # í…ìŠ¤íŠ¸ ì…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_input:
        if not st.session_state.session_id:
            st.error("ì„¸ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        image_data = None
        image_display = None
        if uploaded_image is not None:
            image = Image.open(uploaded_image)
            buffer = io.BytesIO()
            image.save(buffer, format="PNG")
            image_data = base64.b64encode(buffer.getvalue()).decode()
            image_display = image
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_message = {
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now()
        }
        if image_display:
            user_message["image"] = image_display
        
        st.session_state.messages.append(user_message)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(user_input)
            if image_display:
                st.image(image_display, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€", width=300)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            result = process_enhanced_query_with_progress(user_input, image_data)
            
            if result:
                response_content = result.get("content", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown(response_content)
                
                # ê°œì„ ëœ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                metadata = result.get("metadata", {})
                response_metadata = result.get("response_metadata", {})
                
                # ì˜ë„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                if "intent_analysis" in result:
                    display_intent_analysis_results(result["intent_analysis"])
                
                # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                if "search_quality" in metadata:
                    display_search_quality_metrics({"quality_metrics": metadata["search_quality"]})
                
                # ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                if response_metadata:
                    display_response_quality_metrics(response_metadata)
                
                # Citation í‘œì‹œ
                citations = result.get("citations", [])
                if citations:
                    try:
                        from ui.app import display_citation_expandable_with_id
                        new_response_id = f"safe_new_{int(time.time() * 1000)}"
                        display_citation_expandable_with_id(citations, response_content, new_response_id)
                    except ImportError:
                        # ê¸°ë³¸ Citation í‘œì‹œ
                        st.markdown("### ğŸ“š ì°¸ê³  ë¬¸ì„œ")
                        for i, citation in enumerate(citations, 1):
                            filename = citation.get("document_title", f"ë¬¸ì„œ_{i}")
                            with st.expander(f"[{i}] {filename}", expanded=False):
                                preview = citation.get("preview", "")
                                if preview:
                                    st.text_area("ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", value=preview, height=100, disabled=True)
                
                # ì„¸ì…˜ì— AI ì‘ë‹µ ì¶”ê°€
                ai_message = {
                    "role": "assistant",
                    "content": response_content,
                    "citations": citations,
                    "metadata": {
                        "processing_time": result.get('total_processing_time', 0),
                        "iterations_used": result.get('iterations_used', 0),
                        "primary_intent": metadata.get('primary_intent', 'unknown'),
                        "search_quality": metadata.get('search_quality', {}),
                        "response_quality": response_metadata.get('response_quality', {}),
                        "token_usage": response_metadata.get('token_usage', {}),
                        "enhanced_features": result.get('enhanced_features', {})
                    },
                    "timestamp": datetime.now()
                }
                st.session_state.messages.append(ai_message)
            else:
                st.error("ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()

"""
Improved MCP RAG Chatbot - Final Safe Streamlit UI
Citation í‘œì‹œ ê¸°ëŠ¥ì´ í¬í•¨ëœ ìµœì¢… ì•ˆì „í•œ UI
"""

import streamlit as st
import sys
import os
import base64
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from PIL import Image
import io
import time
import threading
from queue import Queue

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (ì»¨í…Œì´ë„ˆ í™˜ê²½ ëŒ€ì‘)
import os
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)  # /app ë””ë ‰í† ë¦¬
sys.path.append(project_root)

# ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° import
from utils.image_utils import process_image_for_bedrock, get_image_info

from src.agents.react_agent_improved_safe import improved_react_agent
from src.utils.session import SessionManager
from config.settings import settings
from ui.citation_display import display_citation_expandable_with_id, display_citation_expandable

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Agentic RAG chatbot",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "session_id" not in st.session_state:
    st.session_state.session_id = None
if "improved_react_agent" not in st.session_state:
    st.session_state.improved_react_agent = None
if "session_manager" not in st.session_state:
    st.session_state.session_manager = None
if "kb_id" not in st.session_state:
    st.session_state.kb_id = "CQLBN9MFDZ"
if "ui_updates" not in st.session_state:
    st.session_state.ui_updates = Queue()
if "current_progress" not in st.session_state:
    st.session_state.current_progress = {}


def initialize_improved_agents(kb_id: str):
    """ê°œì„ ëœ Agent ë° ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
    try:
        # KB_ID ì„¤ì • ì—…ë°ì´íŠ¸
        settings.knowledge_base.kb_id = kb_id
        
        # ê°œì„ ëœ Agent ì´ˆê¸°í™” (ì•ˆì „í•œ ë²„ì „)
        react_agent = improved_react_agent
        session_manager = SessionManager()
        
        return react_agent, session_manager
    except Exception as e:
        st.error(f"ê°œì„ ëœ Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None, None


def ui_callback(update_type: str, data: Dict[str, Any]):
    """UI ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜"""
    try:
        # ì„¸ì…˜ ìƒíƒœì— ì—…ë°ì´íŠ¸ ì €ì¥
        st.session_state.ui_updates.put({
            "type": update_type,
            "data": data,
            "timestamp": datetime.now().isoformat()
        })
        
        # í˜„ì¬ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        if update_type == "stage_update":
            stage = data.get("stage", "unknown")
            message = data.get("message", "")
            st.session_state.current_progress[stage] = {
                "message": message,
                "timestamp": datetime.now().isoformat(),
                "data": data
            }
        elif update_type in ["tool_call_start", "tool_call_complete", "tool_call_failed"]:
            # Tool í˜¸ì¶œ ì •ë³´ ì—…ë°ì´íŠ¸
            call_info = data
            call_id = call_info.get("call_id", "unknown")
            st.session_state.current_progress[f"tool_call_{call_id}"] = call_info
            
    except Exception as e:
        print(f"UI ì½œë°± ì˜¤ë¥˜: {e}")


def display_enhanced_progress():
    """ê°œì„ ëœ ì§„í–‰ ìƒí™© í‘œì‹œ"""
    if not st.session_state.current_progress:
        return
    
    progress_container = st.container()
    
    with progress_container:
        st.markdown("### ğŸ”„ ì²˜ë¦¬ ì§„í–‰ ìƒí™©")
        
        # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™©
        stages = [
            ("intent_analysis", "ğŸ§  ì˜ë„ ë¶„ì„"),
            ("multi_stage_search", "ğŸ” ë‹¤ë‹¨ê³„ ê²€ìƒ‰"),
            ("response_generation", "ğŸ“ ì‘ë‹µ ìƒì„±")
        ]
        
        cols = st.columns(len(stages))
        
        for i, (stage_key, stage_name) in enumerate(stages):
            with cols[i]:
                if stage_key in st.session_state.current_progress:
                    stage_info = st.session_state.current_progress[stage_key]
                    message = stage_info.get("message", "")
                    
                    if "ì™„ë£Œ" in message or "âœ…" in message:
                        st.success(f"{stage_name} âœ…")
                    elif "ì¤‘" in message or "â³" in message:
                        st.info(f"{stage_name} â³")
                    else:
                        st.info(f"{stage_name} â¸ï¸")
                else:
                    st.info(f"{stage_name} â¸ï¸")
        
        # Tool í˜¸ì¶œ ìƒì„¸ ì •ë³´
        tool_calls = [
            key for key in st.session_state.current_progress.keys() 
            if key.startswith("tool_call_")
        ]
        
        if tool_calls:
            st.markdown("#### ğŸ”§ MCP Tool í˜¸ì¶œ ìƒí™©")
            
            for tool_call_key in tool_calls[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
                call_info = st.session_state.current_progress[tool_call_key]
                ui_message = call_info.get("ui_message", "")
                status = call_info.get("status", "unknown")
                
                if status == "completed":
                    st.success(ui_message)
                elif status == "running":
                    st.info(ui_message)
                elif status == "failed":
                    st.error(ui_message)
                else:
                    st.info(ui_message)


def display_intent_analysis_results(analysis_result: Dict[str, Any]):
    """ì˜ë„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    if not analysis_result:
        return
    
    with st.expander("ğŸ§  ì˜ë„ ë¶„ì„ ê²°ê³¼", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "ì£¼ìš” ì˜ë„", 
                analysis_result.get("primary_intent", "unknown").replace("_", " ")
            )
        
        with col2:
            st.metric(
                "ë³µì¡ë„", 
                analysis_result.get("complexity", "ë³´í†µ")
            )
        
        with col3:
            additional_searches = analysis_result.get("requires_additional_search", False)
            st.metric(
                "ì¶”ê°€ ê²€ìƒ‰", 
                "í•„ìš”" if additional_searches else "ë¶ˆí•„ìš”"
            )
        
        # ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬
        additional_queries = analysis_result.get("additional_search_queries", [])
        if additional_queries:
            st.markdown("**ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬:**")
            for i, query in enumerate(additional_queries, 1):
                st.markdown(f"{i}. {query}")
        
        # í•µì‹¬ ì—”í‹°í‹°
        key_entities = analysis_result.get("key_entities", [])
        if key_entities:
            st.markdown("**í•µì‹¬ ì—”í‹°í‹°:**")
            st.markdown(", ".join(key_entities))


def display_search_quality_metrics(search_results: Dict[str, Any]):
    """ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ"""
    quality_metrics = search_results.get("quality_metrics", {})
    if not quality_metrics:
        return
    
    with st.expander("ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­", expanded=False):
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ì „ì²´ í’ˆì§ˆ", 
                f"{quality_metrics.get('overall_quality', 0):.2f}",
                help="ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆ ì ìˆ˜"
            )
        
        with col2:
            st.metric(
                "ê´€ë ¨ì„±", 
                f"{quality_metrics.get('relevance_score', 0):.2f}",
                help="ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± ì ìˆ˜"
            )
        
        with col3:
            st.metric(
                "ì»¤ë²„ë¦¬ì§€", 
                f"{quality_metrics.get('coverage_score', 0):.2f}",
                help="í•µì‹¬ ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€ ì ìˆ˜"
            )
        
        with col4:
            st.metric(
                "ë‹¤ì–‘ì„±", 
                f"{quality_metrics.get('diversity_score', 0):.2f}",
                help="ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„± ì ìˆ˜"
            )


def display_response_quality_metrics(response_metadata: Dict[str, Any]):
    """ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ"""
    response_quality = response_metadata.get("response_quality", {})
    token_usage = response_metadata.get("token_usage", {})
    
    if not response_quality and not token_usage:
        return
    
    with st.expander("ğŸ“ ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­", expanded=False):
        if response_quality:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ì „ì²´ í’ˆì§ˆ", 
                    f"{response_quality.get('overall_quality', 0):.2f}"
                )
            
            with col2:
                st.metric(
                    "êµ¬ì¡°í™” ì ìˆ˜", 
                    f"{response_quality.get('structure_score', 0):.2f}"
                )
            
            with col3:
                st.metric(
                    "ì˜ë„ ì¶©ì¡±ë„", 
                    f"{response_quality.get('intent_score', 0):.2f}"
                )
            
            with col4:
                st.metric(
                    "Citation í™œìš©", 
                    f"{response_quality.get('citation_score', 0):.2f}"
                )
        
        if token_usage:
            st.markdown("**í† í° ì‚¬ìš©ëŸ‰:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì´ í† í°", token_usage.get("total_tokens", 0))
            
            with col2:
                st.metric("ë‹¨ì–´ ìˆ˜", token_usage.get("word_count", 0))
            
            with col3:
                utilization = token_usage.get("utilization_rate", 0)
                st.metric("ì‚¬ìš©ë¥ ", f"{utilization}%")
                
                # ì‚¬ìš©ë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                if utilization > 90:
                    st.warning("í† í° ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ (90% ì´ìƒ)")
                elif utilization > 70:
                    st.info("í† í° ì‚¬ìš©ë¥ ì´ ì ì ˆí•©ë‹ˆë‹¤ (70-90%)")


def process_enhanced_query_with_progress(query: str, image_data: Optional[str] = None):
    """ê°œì„ ëœ ì§„í–‰ ìƒí™© í‘œì‹œì™€ í•¨ê»˜ ì¿¼ë¦¬ ì²˜ë¦¬"""
    
    # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
    st.session_state.current_progress = {}
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ ì˜ì—­
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    
    try:
        # 1ë‹¨ê³„: ì˜ë„ ë¶„ì„ ì‹œì‘
        with progress_placeholder.container():
            st.markdown("### ğŸ”„ ì²˜ë¦¬ ì¤‘...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            status_text.text("ğŸ§  ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì¤‘...")
        
        # ê°œì„ ëœ ReAct Agentë¡œ ì²˜ë¦¬ (ì•ˆì „í•œ ë²„ì „)
        def progress_callback(stage, message, progress=None):
            """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì½œë°±"""
            try:
                with progress_placeholder.container():
                    st.markdown("### ğŸ”„ ì²˜ë¦¬ ì¤‘...")
                    
                    if progress is not None:
                        progress_bar = st.progress(progress / 100)
                    else:
                        progress_bar = st.progress(0)
                    
                    # ë‹¨ê³„ë³„ ìƒíƒœ í‘œì‹œ
                    if stage == "intent_analysis":
                        status_text = st.empty()
                        status_text.text(f"ğŸ§  {message}")
                        if progress is None:
                            progress_bar.progress(10)
                    elif stage == "kb_search":
                        status_text = st.empty()
                        status_text.text(f"ğŸ” {message}")
                        if progress is None:
                            progress_bar.progress(30)
                    elif stage == "multi_stage_search":
                        status_text = st.empty()
                        status_text.text(f"ğŸ” {message}")
                        if progress is None:
                            progress_bar.progress(60)
                    elif stage == "response_generation":
                        status_text = st.empty()
                        status_text.text(f"ğŸ“ {message}")
                        if progress is None:
                            progress_bar.progress(80)
                    elif stage == "complete":
                        status_text = st.empty()
                        status_text.text(f"âœ… {message}")
                        progress_bar.progress(100)
                        
            except Exception as e:
                print(f"Progress callback error: {e}")
        
        # ì»¤ìŠ¤í…€ UI ì½œë°± í•¨ìˆ˜
        def enhanced_ui_callback(update_type: str, data: Dict[str, Any]):
            """í–¥ìƒëœ UI ì½œë°±"""
            try:
                if update_type == "stage_update":
                    stage = data.get("stage", "unknown")
                    message = data.get("message", "ì²˜ë¦¬ ì¤‘...")
                    progress = data.get("progress")
                    progress_callback(stage, message, progress)
                    
                elif update_type == "tool_call_start":
                    tool_name = data.get("tool_name", "ë„êµ¬")
                    if "kb" in tool_name.lower() or "search" in tool_name.lower():
                        progress_callback("kb_search", f"KB ê²€ìƒ‰ ì‹¤í–‰ ì¤‘... ({tool_name})")
                    else:
                        progress_callback("processing", f"ë„êµ¬ ì‹¤í–‰ ì¤‘... ({tool_name})")
                        
                elif update_type == "tool_call_complete":
                    tool_name = data.get("tool_name", "ë„êµ¬")
                    duration = data.get("duration", 0)
                    if "kb" in tool_name.lower() or "search" in tool_name.lower():
                        progress_callback("kb_search", f"KB ê²€ìƒ‰ ì™„ë£Œ ({duration:.2f}ì´ˆ)")
                    
                elif update_type == "search_stage_complete":
                    stage_num = data.get("stage_number", 0)
                    total_stages = data.get("total_stages", 1)
                    progress_callback("multi_stage_search", 
                                    f"ê²€ìƒ‰ ë‹¨ê³„ {stage_num}/{total_stages} ì™„ë£Œ")
                    
            except Exception as e:
                print(f"Enhanced UI callback error: {e}")
        
        # ì²˜ë¦¬ ì‹œì‘
        result = st.session_state.improved_react_agent.process_query_enhanced(
            user_query=query,
            session_id=st.session_state.session_id,
            image_data=image_data,
            ui_callback=enhanced_ui_callback
        )
        
        # ìµœì¢… ì™„ë£Œ ìƒíƒœ í‘œì‹œ
        progress_callback("complete", "ì²˜ë¦¬ ì™„ë£Œ!", 100)
        
        # ì ì‹œ í›„ ì§„í–‰ ìƒí™© í‘œì‹œ ì œê±°
        import time
        time.sleep(1)
        progress_placeholder.empty()
        
        # ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ (ê°„ë‹¨í•˜ê²Œ)
        with status_placeholder.container():
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result.get('total_processing_time', 0):.1f}ì´ˆ")
            
            with col2:
                st.metric("Citation ìˆ˜", f"{len(result.get('citations', []))}")
            
            with col3:
                search_stages = len(result.get("metadata", {}).get("search_stages", []))
                st.metric("ê²€ìƒ‰ ë‹¨ê³„", f"{search_stages}ë‹¨ê³„")
        
        return result
        
    except Exception as e:
        with progress_placeholder.container():
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def main():
    # í—¤ë”
    st.title("ğŸ¤– Agentic RAG chatbot")
    
    # ê³ ì •ëœ ë ˆì¸ë³´ìš° ê·¸ë¼ë°ì´ì…˜ ì´íƒ¤ë¦­ì²´ í…ìŠ¤íŠ¸ (ì™¼ìª½ ì •ë ¬)
    st.markdown("""
    <style>
    .rainbow-subtitle-docker {
        font-style: italic;
        font-size: 16px;
        background: linear-gradient(90deg, 
            #ff0000, #ff7f00, #ffff00, #00ff00, 
            #0000ff, #4b0082, #9400d3);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        text-align: left;
        margin-bottom: 20px;
        font-weight: 500;
    }
    </style>
    <div class="rainbow-subtitle-docker">ê°œì„ ëœ ReAct ê¸°ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ - ì™„ì „í•œ Citation í‘œì‹œ ì§€ì›</div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ê°œì„ ëœ ì„¤ì • (Final)")
        
        # KB_ID ì„¤ì •
        st.subheader("Knowledge Base ì„¤ì •")
        new_kb_id = st.text_input(
            "KB_ID",
            value=st.session_state.kb_id,
            help="Amazon Bedrock Knowledge Base ID"
        )
        
        if new_kb_id != st.session_state.kb_id:
            st.session_state.kb_id = new_kb_id
            st.session_state.improved_react_agent = None
            st.session_state.session_manager = None
            st.rerun()
        
        # ê°œì„ ëœ Agent ì´ˆê¸°í™”
        if st.session_state.improved_react_agent is None or st.session_state.session_manager is None:
            with st.spinner("ê°œì„ ëœ Agent ì´ˆê¸°í™” ì¤‘..."):
                react_agent, session_manager = initialize_improved_agents(st.session_state.kb_id)
                if react_agent and session_manager:
                    st.session_state.improved_react_agent = react_agent
                    st.session_state.session_manager = session_manager
                    st.success("ê°œì„ ëœ Agent ì´ˆê¸°í™” ì™„ë£Œ!")
                else:
                    st.error("Agent ì´ˆê¸°í™” ì‹¤íŒ¨")
                    st.stop()
        
        # ì„¸ì…˜ ê´€ë¦¬
        st.subheader("ì„¸ì…˜ ê´€ë¦¬")
        if st.button("ğŸ†• ìƒˆ ëŒ€í™” ì‹œì‘"):
            if st.session_state.session_manager:
                session = st.session_state.session_manager.create_session()
                st.session_state.session_id = session.session_id
                st.session_state.messages = []
                st.session_state.current_progress = {}
                st.success("ìƒˆ ì„¸ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        if st.session_state.session_id:
            st.info(f"ì„¸ì…˜ ID: {st.session_state.session_id[:8]}...")
        
        st.divider()
        
        # ê°œì„ ëœ ì‹œìŠ¤í…œ ì •ë³´
        st.subheader("ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ì‹œìŠ¤í…œ ê²€ì¦
        if st.session_state.improved_react_agent:
            validation_result = st.session_state.improved_react_agent.validate_enhanced_system()
            system_status = validation_result.get("system_status", "unknown")
            
            if system_status == "healthy":
                st.success("âœ… ëª¨ë“  ê°œì„  ê¸°ëŠ¥ ì •ìƒ ì‘ë™")
            elif system_status == "degraded":
                st.warning(f"âš ï¸ ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ: {validation_result.get('issues', '')}")
            else:
                st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {validation_result.get('error', '')}")
        
        # ê°œì„  ê¸°ëŠ¥ ëª©ë¡
        st.info(f"""
        **ê°œì„ ëœ ê¸°ëŠ¥ë“¤ (Final Version):**
        ğŸ§  **ì˜ë„ ë¶„ì„**: ì‚¬ìš©ì ì¿¼ë¦¬ ì˜ë„ ìë™ íŒŒì•…
        ğŸ” **ë‹¤ë‹¨ê³„ ê²€ìƒ‰**: 1ì°¨ ê²€ìƒ‰ + ì¶”ê°€ ê²€ìƒ‰ (ìµœëŒ€ 5íšŒ)
        ğŸ“ **í† í° ì œí•œ**: 3000 í† í° ì´ë‚´ ì‘ë‹µ ìƒì„± (ì•ˆì „ ì²˜ë¦¬)
        ğŸ”§ **Tool ì¶”ì **: MCP Tool í˜¸ì¶œ ì‹¤ì‹œê°„ í‘œì‹œ
        ğŸ“Š **í’ˆì§ˆ ë©”íŠ¸ë¦­**: ê²€ìƒ‰ ë° ì‘ë‹µ í’ˆì§ˆ ì¸¡ì •
        ğŸ“š **Citation í‘œì‹œ**: ì™„ì „í•œ íŒŒì¼ëª… ë° ë‚´ìš© í‘œì‹œ
        
        **KB_ID**: {st.session_state.kb_id}
        **ëª¨ë¸**: Claude 3.7 Sonnet
        **í† í° ì²˜ë¦¬**: tiktoken ì•ˆì „ fallback ì§€ì›
        **Citation**: íŒŒì¼ëª… ì¶”ì¶œ ë° í™•ì¥ í‘œì‹œ
        """)
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    if not st.session_state.session_id and st.session_state.session_manager:
        session = st.session_state.session_manager.create_session()
        st.session_state.session_id = session.session_id
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            if message["role"] == "user":
                st.markdown(message["content"])
                if "image" in message:
                    st.image(message["image"], caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€", width=300)
            else:
                st.markdown(message["content"])
                
                # ê°œì„ ëœ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                if "metadata" in message:
                    metadata = message["metadata"]
                    
                    # ì˜ë„ ë¶„ì„ ê²°ê³¼
                    if "intent_analysis" in metadata:
                        display_intent_analysis_results(metadata["intent_analysis"])
                    
                    # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­
                    if "search_quality" in metadata:
                        display_search_quality_metrics({"quality_metrics": metadata["search_quality"]})
                    
                    # ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­
                    if "response_quality" in metadata or "token_usage" in metadata:
                        display_response_quality_metrics({
                            "response_quality": metadata.get("response_quality", {}),
                            "token_usage": metadata.get("token_usage", {})
                        })
                
                # Citation í‘œì‹œ - ê°œì„ ëœ ë²„ì „
                if "citations" in message and message["citations"]:
                    message_id = f"final_msg_{idx}_{hash(str(message.get('timestamp', '')))}"
                    display_citation_expandable_with_id(message["citations"], message["content"], message_id)
    
    # ì±„íŒ… ì…ë ¥ ì˜ì—­
    st.markdown("### ğŸ’¬ ë©”ì‹œì§€ ì…ë ¥")
    
    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ ì²¨ë¶€ (ì„ íƒì‚¬í•­)",
        type=['png', 'jpg', 'jpeg'],
        help="ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    # í…ìŠ¤íŠ¸ ì…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_input:
        if not st.session_state.session_id:
            st.error("ì„¸ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ (5MB ì œí•œ ëŒ€ì‘)
        image_data = None
        image_display = None
        if uploaded_image is not None:
            # ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´ í‘œì‹œ
            original_image = Image.open(uploaded_image)
            original_info = get_image_info(original_image)
            
            # 5MB ì´ˆê³¼ ì‹œ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
            if original_info["size_mb"] > 5.0:
                st.warning(f"âš ï¸ ì´ë¯¸ì§€ í¬ê¸°ê°€ {original_info['size_mb']}MBë¡œ Bedrock ì œí•œ(5MB)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë¦¬ì‚¬ì´ì§•í•©ë‹ˆë‹¤.")
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì§• í¬í•¨)
            with st.spinner("ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘..."):
                image_data, image_display = process_image_for_bedrock(uploaded_image)
            
            if image_data is None:
                st.error("âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                return
            
            # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì •ë³´ í‘œì‹œ
            processed_info = get_image_info(image_display)
            if original_info["size_mb"] > 5.0:
                st.success(f"âœ… ì´ë¯¸ì§€ê°€ {processed_info['size_mb']}MBë¡œ ë¦¬ì‚¬ì´ì§•ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.info(f"ğŸ“Š ì›ë³¸: {original_info['width']}x{original_info['height']} ({original_info['size_mb']}MB) â†’ ì²˜ë¦¬ë¨: {processed_info['width']}x{processed_info['height']} ({processed_info['size_mb']}MB)")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_message = {
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now()
        }
        if image_display:
            user_message["image"] = image_display
        
        st.session_state.messages.append(user_message)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(user_input)
            if image_display:
                st.image(image_display, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€", width=300)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            result = process_enhanced_query_with_progress(user_input, image_data)
            
            if result:
                response_content = result.get("content", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown(response_content)
                
                # ê°œì„ ëœ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                metadata = result.get("metadata", {})
                response_metadata = result.get("response_metadata", {})
                
                # ì˜ë„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                if "intent_analysis" in result:
                    display_intent_analysis_results(result["intent_analysis"])
                
                # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                if "search_quality" in metadata:
                    display_search_quality_metrics({"quality_metrics": metadata["search_quality"]})
                
                # ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                if response_metadata:
                    display_response_quality_metrics(response_metadata)
                
                # Citation í‘œì‹œ - ê°œì„ ëœ ë²„ì „
                citations = result.get("citations", [])
                if citations:
                    new_response_id = f"final_new_{int(time.time() * 1000)}"
                    display_citation_expandable_with_id(citations, response_content, new_response_id)
                
                # ì„¸ì…˜ì— AI ì‘ë‹µ ì¶”ê°€
                ai_message = {
                    "role": "assistant",
                    "content": response_content,
                    "citations": citations,
                    "metadata": {
                        "processing_time": result.get('total_processing_time', 0),
                        "iterations_used": result.get('iterations_used', 0),
                        "primary_intent": metadata.get('primary_intent', 'unknown'),
                        "search_quality": metadata.get('search_quality', {}),
                        "response_quality": response_metadata.get('response_quality', {}),
                        "token_usage": response_metadata.get('token_usage', {}),
                        "enhanced_features": result.get('enhanced_features', {})
                    },
                    "timestamp": datetime.now()
                }
                st.session_state.messages.append(ai_message)
            else:
                st.error("ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
